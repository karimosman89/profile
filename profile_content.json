{
  "en": {
    "HEADLINE": "Ship Reliable AI to Production—Fast",
    "SUMMARY_TITLE": "Impact-Driven AI Engineer",
    "SUMMARY_P1": "I design, build, and operate production-grade AI systems that turn research into measurable business outcomes. My focus is on Large Language Models (LLMs), Retrieval-Augmented Generation (RAG), and Computer Vision—delivered with enterprise-grade reliability, governance, and cost efficiency.",
    "SUMMARY_P2": "From model selection and fine-tuning to scalable inference and monitoring, I bring a full-stack approach: data pipelines, evaluation harnesses, latency/cost optimization, observability, and safety guardrails. I work across teams—product, security, and infrastructure—to ensure AI features ship on time and perform at scale.",
    "SUMMARY_P3": "I communicate complex technical topics clearly to executives and engineers alike and translate strategy into execution. My track record includes shipping multilingual RAG assistants, real-time vision systems at the edge, and automated ML platforms—each with quantified impact and rigorous MLOps practices.",
    "SKILLS_TITLE": "Technical Expertise",
    "SKILL_LANGUAGES": ["Python", "TypeScript", "JavaScript", "Go", "SQL", "Bash", "C++"],
    "SKILL_FRAMEWORKS": ["PyTorch", "TensorFlow", "JAX", "Hugging Face Transformers", "LangChain", "LlamaIndex", "OpenAI API", "FastAPI", "Streamlit", "Gradio", "OpenCV", "ONNX Runtime", "TensorRT"],
    "SKILL_MLOPS": ["Kubernetes", "Docker", "AWS", "GCP", "Azure", "MLflow", "Weights & Biases", "Ray", "Apache Kafka", "Airflow", "Feast", "KServe", "Triton Inference Server", "Terraform", "Prometheus/Grafana", "Datadog"],
    "PROJECT_1_TITLE": "Multilingual RAG Assistant for Global Support",
    "PROJECT_1_CHALLENGE": "A global support team handled 120k+ tickets/month across 8 languages, with inconsistent answers and a 36-hour median resolution time. Manual triage and knowledge search drove high costs and low CSAT in non-English markets.",
    "PROJECT_1_SOLUTION": "Built a production RAG system with cross-lingual embeddings, vector search (FAISS/PGVector), and a distilled LLM (Llama 3.1 8B) fine-tuned on conversation transcripts. Implemented evaluation harness (faithfulness, toxicity, bias), caching, prompt versioning, and safety guardrails. Delivered a Streamlit st.chat interface with role-based access, analytics, and audit logs.",
    "PROJECT_1_IMPACT": "42% ticket deflection in 90 days, 68% faster median resolution, 35% cost reduction per ticket, +12 CSAT points in non-English locales, 99.9% uptime with blue/green releases.",
    "PROJECT_2_TITLE": "Real-time Edge Vision Inspection for Manufacturing",
    "PROJECT_2_CHALLENGE": "A high-throughput assembly line struggled with undetected micro-defects, causing returns and warranty claims. Manual inspection limited throughput and introduced variability, with 1.8% escape rate and 7.5s average cycle time.",
    "PROJECT_2_SOLUTION": "Trained a custom YOLOv8 model with targeted augmentations and hard-negative mining, then pruned and INT8-quantized for TensorRT on NVIDIA Jetson. Deployed via Triton/KServe with GPU autoscaling and OpenCV pre/post-processing. Streamlit dashboard (st.image) provided real-time QA, drift monitoring, and operator feedback loops.",
    "PROJECT_2_IMPACT": "98.7% recall and 96.2% precision in production, cycle time reduced to 3.1s, defect escape rate cut to 0.3%, scrap reduced by 22%, and OEE improved by 6.4 points."
  },
  "fr": {
    "HEADLINE": "Déployer une IA fiable en production — rapidement",
    "SUMMARY_TITLE": "Ingénieur IA orienté impact",
    "SUMMARY_P1": "Je conçois, développe et exploite des systèmes d’IA prêts pour la production, transformant la recherche en résultats métiers mesurables. Mon expertise couvre les LLM, le RAG (Retrieval‑Augmented Generation) et la Vision par Ordinateur, avec un niveau industriel en fiabilité, conformité et optimisation des coûts.",
    "SUMMARY_P2": "De la sélection et l’adaptation de modèles à l’inférence à grande échelle et au monitoring, j’adopte une approche full‑stack : pipelines de données, bancs d’évaluation, optimisation latence/coût, observabilité et garde‑fous de sécurité. Je collabore avec les équipes produit, sécurité et infrastructure pour livrer des fonctionnalités IA performantes à l’échelle.",
    "SUMMARY_P3": "Je vulgarise les sujets techniques complexes pour les dirigeants comme pour les ingénieurs, et je transforme la stratégie en exécution. Mon expérience inclut le déploiement d’assistants RAG multilingues, de systèmes de vision temps réel en périphérie, et de plateformes ML automatisées — avec impact chifré et MLOps rigoureux.",
    "SKILLS_TITLE": "Compétences techniques",
    "SKILL_LANGUAGES": ["Python", "TypeScript", "JavaScript", "Go", "SQL", "Bash", "C++"],
    "SKILL_FRAMEWORKS": ["PyTorch", "TensorFlow", "JAX", "Hugging Face Transformers", "LangChain", "LlamaIndex", "OpenAI API", "FastAPI", "Streamlit", "Gradio", "OpenCV", "ONNX Runtime", "TensorRT"],
    "SKILL_MLOPS": ["Kubernetes", "Docker", "AWS", "GCP", "Azure", "MLflow", "Weights & Biases", "Ray", "Apache Kafka", "Airflow", "Feast", "KServe", "Triton Inference Server", "Terraform", "Prometheus/Grafana", "Datadog"],
    "PROJECT_1_TITLE": "Assistant RAG multilingue pour le support global",
    "PROJECT_1_CHALLENGE": "L’équipe support gérait plus de 120k tickets/mois en 8 langues, avec des réponses inégales et 36 h de médiane de résolution. Le tri manuel et la recherche de connaissances entraînaient des coûts élevés et un CSAT faible sur les marchés non anglophones.",
    "PROJECT_1_SOLUTION": "Mise en place d’un RAG de production avec embeddings cross‑lingues, recherche vectorielle (FAISS/PGVector) et LLM distillé (Llama 3.1 8B) affiné sur des transcriptions de conversations. Ajout d’un banc d’évaluation (fidélité, toxicité, biais), cache, versioning de prompts et garde‑fous. Interface Streamlit st.chat avec contrôle d’accès, analytics et journalisation d’audit.",
    "PROJECT_1_IMPACT": "42 % de déflexion des tickets en 90 jours, résolution médiane 68 % plus rapide, coûts par ticket réduits de 35 %, +12 points de CSAT sur les zones non anglophones, 99,9 % de disponibilité grâce aux déploiements blue/green.",
    "PROJECT_2_TITLE": "Inspection visuelle temps réel en périphérie (edge)",
    "PROJECT_2_CHALLENGE": "Une ligne d’assemblage à grand débit laissait passer des micro‑défauts, générant retours et garanties. L’inspection manuelle limitait le débit et introduisait de la variabilité, avec 1,8 % de défauts échappés et 7,5 s de temps de cycle moyen.",
    "PROJECT_2_SOLUTION": "Entraînement d’un modèle YOLOv8 personnalisé avec augmentations ciblées et hard‑negative mining, puis pruning et quantification INT8 pour TensorRT sur NVIDIA Jetson. Déploiement via Triton/KServe avec autoscaling GPU et pré/post‑traitements OpenCV. Tableau de bord Streamlit (st.image) pour QA temps réel, suivi de dérive et boucle de feedback opérateur.",
    "PROJECT_2_IMPACT": "Rappel de 98,7 % et précision de 96,2 % en production, temps de cycle réduit à 3,1 s, taux d’évasion à 0,3 %, rebuts −22 %, OEE +6,4 points."
  },
  "de": {
    "HEADLINE": "Zuverlässige KI in Produktion bringen — schnell",
    "SUMMARY_TITLE": "Impact‑getriebener KI‑Engineer",
    "SUMMARY_P1": "Ich entwickle und betreibe produktionsreife KI‑Systeme, die Forschung in messbaren Geschäftswert übersetzen. Mein Schwerpunkt liegt auf LLMs, Retrieval‑Augmented Generation (RAG) und Computer Vision — mit Unternehmens‑Reliabilität, Governance und Kosteneffizienz.",
    "SUMMARY_P2": "Von Modellauswahl und Feintuning über skalierbare Inferenz bis Monitoring verfolge ich einen Full‑Stack‑Ansatz: Datenpipelines, Evaluations‑Harnesses, Latenz-/Kosten‑Optimierung, Observability und Safety‑Guardrails. In cross‑funktionalen Teams sorge ich dafür, dass KI‑Features pünktlich und skalierbar live gehen.",
    "SUMMARY_P3": "Komplexe Technik vermittle ich klar an Management und Engineering und setze Strategie konsequent um. Erfolgreiche Deliverables umfassen mehrsprachige RAG‑Assistenten, Echtzeit‑Vision am Edge und automatisierte ML‑Plattformen — jeweils mit quantifiziertem Impact und robusten MLOps‑Praktiken.",
    "SKILLS_TITLE": "Technische Expertise",
    "SKILL_LANGUAGES": ["Python", "TypeScript", "JavaScript", "Go", "SQL", "Bash", "C++"],
    "SKILL_FRAMEWORKS": ["PyTorch", "TensorFlow", "JAX", "Hugging Face Transformers", "LangChain", "LlamaIndex", "OpenAI API", "FastAPI", "Streamlit", "Gradio", "OpenCV", "ONNX Runtime", "TensorRT"],
    "SKILL_MLOPS": ["Kubernetes", "Docker", "AWS", "GCP", "Azure", "MLflow", "Weights & Biases", "Ray", "Apache Kafka", "Airflow", "Feast", "KServe", "Triton Inference Server", "Terraform", "Prometheus/Grafana", "Datadog"],
    "PROJECT_1_TITLE": "Mehrsprachiger RAG‑Assistent für globalen Support",
    "PROJECT_1_CHALLENGE": "Ein globales Supportteam bearbeitete 120k+ Tickets/Monat in 8 Sprachen, mit inkonsistenten Antworten und 36 Stunden Median‑Lösungszeit. Manuelles Triage und Wissenssuche verursachten hohe Kosten und niedrige CSAT‑Werte in Nicht‑Englisch‑Märkten.",
    "PROJECT_1_SOLUTION": "Aufbau eines produktionsreifen RAG mit cross‑lingualen Embeddings, Vektorsuche (FAISS/PGVector) und distilliertem LLM (Llama 3.1 8B) feingetunt auf Gesprächstranskripten. Evaluations‑Harness (Fidelity, Toxicity, Bias), Caching, Prompt‑Versionierung und Safety‑Guardrails. Streamlit st.chat‑UI mit rollenbasiertem Zugriff, Analytics und Audit‑Logs.",
    "PROJECT_1_IMPACT": "42 % Ticket‑Deflection in 90 Tagen, 68 % schnellere Median‑Lösung, 35 % geringere Ticketkosten, +12 CSAT‑Punkte in Nicht‑Englisch‑Regionen, 99,9 % Verfügbarkeit via Blue/Green‑Deployments.",
    "PROJECT_2_TITLE": "Echtzeit‑Edge‑Vision für die Fertigungsprüfung",
    "PROJECT_2_CHALLENGE": "Eine Hochdurchsatz‑Montagelinie übersah Mikrofehler, was Rücksendungen und Garantieansprüche auslöste. Manuelle Inspektion begrenzte den Durchsatz und war variabel; 1,8 % Escape‑Rate bei 7,5 s durchschnittlicher Taktzeit.",
    "PROJECT_2_SOLUTION": "Custom YOLOv8 mit gezielten Augmentierungen und Hard‑Negative‑Mining trainiert, anschließend Pruning und INT8‑Quantisierung für TensorRT auf NVIDIA Jetson. Deployment über Triton/KServe mit GPU‑Autoscaling und OpenCV‑Pre/Post‑Processing. Streamlit‑Dashboard (st.image) für Live‑QA, Drift‑Monitoring und Operator‑Feedback.",
    "PROJECT_2_IMPACT": "98,7 % Recall und 96,2 % Precision in Produktion, Taktzeit auf 3,1 s reduziert, Escape‑Rate auf 0,3 % gesenkt, Ausschuss −22 %, OEE +6,4 Punkte."
  },
  "es": {
    "HEADLINE": "Llevo IA fiable a producción — rápido",
    "SUMMARY_TITLE": "Ingeniero de IA orientado al impacto",
    "SUMMARY_P1": "Diseño, construyo y opero sistemas de IA listos para producción que convierten la investigación en resultados de negocio medibles. Mi foco: LLMs, RAG y Visión por Computador, con fiabilidad empresarial, gobernanza y eficiencia en costos.",
    "SUMMARY_P2": "Desde la selección y el fine‑tuning del modelo hasta la inferencia a escala y el monitoreo, aporto un enfoque full‑stack: pipelines de datos, marcos de evaluación, optimización de latencia/costo, observabilidad y guardrails de seguridad. Trabajo con producto, seguridad e infraestructura para entregar funcionalidades de IA a escala.",
    "SUMMARY_P3": "Comunico temas técnicos complejos con claridad a ejecutivos y equipos de ingeniería y traduzco la estrategia en ejecución. He lanzado asistentes RAG multilingües, sistemas de visión en tiempo real en el edge y plataformas de ML automatizadas, siempre con impacto cuantificado y prácticas sólidas de MLOps.",
    "SKILLS_TITLE": "Experiencia técnica",
    "SKILL_LANGUAGES": ["Python", "TypeScript", "JavaScript", "Go", "SQL", "Bash", "C++"],
    "SKILL_FRAMEWORKS": ["PyTorch", "TensorFlow", "JAX", "Hugging Face Transformers", "LangChain", "LlamaIndex", "OpenAI API", "FastAPI", "Streamlit", "Gradio", "OpenCV", "ONNX Runtime", "TensorRT"],
    "SKILL_MLOPS": ["Kubernetes", "Docker", "AWS", "GCP", "Azure", "MLflow", "Weights & Biases", "Ray", "Apache Kafka", "Airflow", "Feast", "KServe", "Triton Inference Server", "Terraform", "Prometheus/Grafana", "Datadog"],
    "PROJECT_1_TITLE": "Asistente RAG multilingüe para soporte global",
    "PROJECT_1_CHALLENGE": "Un equipo global gestionaba 120k+ tickets/mes en 8 idiomas, con respuestas inconsistentes y una mediana de resolución de 36 horas. El triage manual y la búsqueda de conocimiento generaban altos costos y bajo CSAT en mercados no angloparlantes.",
    "PROJECT_1_SOLUTION": "Se construyó un RAG de producción con embeddings cross‑lingües, búsqueda vectorial (FAISS/PGVector) y un LLM destilado (Llama 3.1 8B) afinado con transcripciones de conversaciones. Se añadieron banco de evaluación (fidelidad, toxicidad, sesgo), caché, versionado de prompts y guardrails. Interfaz Streamlit st.chat con control de acceso, analítica y auditoría.",
    "PROJECT_1_IMPACT": "42 % de deflexión de tickets en 90 días, mediana de resolución 68 % más rápida, costo por ticket −35 %, +12 puntos de CSAT en mercados no angloparlantes, 99,9 % de disponibilidad con despliegues blue/green.",
    "PROJECT_2_TITLE": "Inspección visual en tiempo real en el edge",
    "PROJECT_2_CHALLENGE": "Una línea de ensamblaje de alto rendimiento no detectaba micro‑defectos, provocando devoluciones y garantías. La inspección manual limitaba el throughput y añadía variabilidad, con 1,8 % de escape y 7,5 s de ciclo.",
    "PROJECT_2_SOLUTION": "Modelo YOLOv8 personalizado con aumentaciones dirigidas y hard‑negative mining; pruning y cuantización INT8 para TensorRT en NVIDIA Jetson. Despliegue con Triton/KServe y autoscaling GPU, pre/post‑proceso con OpenCV. Panel Streamlit (st.image) para QA en vivo, monitoreo de drift y feedback de operadores.",
    "PROJECT_2_IMPACT": "98,7 % de recall y 96,2 % de precisión en producción, ciclo reducido a 3,1 s, tasa de escape a 0,3 %, scrap −22 %, OEE +6,4 puntos."
  },
  "ja": {
    "HEADLINE": "信頼できるAIを迅速に本番運用へ",
    "SUMMARY_TITLE": "成果志向のAIエンジニア",
    "SUMMARY_P1": "研究成果を確かな事業インパクトに変える、本番運用前提のAIシステムを設計・実装・運用します。LLM、RAG（検索拡張生成）、およびコンピュータビジョンに強みがあり、エンタープライズ水準の信頼性・ガバナンス・コスト最適化を徹底します。",
    "SUMMARY_P2": "モデル選定や微調整から、スケーラブルな推論、監視までをフルスタックで対応。データ基盤、評価基盤、レイテンシ/コスト最適化、可観測性、安全ガードレールを一貫して実装します。プロダクト・セキュリティ・インフラ各部門と連携し、期限内にスケールするAI機能を提供します。",
    "SUMMARY_P3": "経営層から開発者まで、技術的な論点を平易に説明し、戦略を実行へ落とし込みます。多言語RAGアシスタント、エッジでのリアルタイム画像検査、ML自動化プラットフォームの本番導入実績があり、定量的な成果と堅牢なMLOpsを重視しています。",
    "SKILLS_TITLE": "技術スキル",
    "SKILL_LANGUAGES": ["Python", "TypeScript", "JavaScript", "Go", "SQL", "Bash", "C++"],
    "SKILL_FRAMEWORKS": ["PyTorch", "TensorFlow", "JAX", "Hugging Face Transformers", "LangChain", "LlamaIndex", "OpenAI API", "FastAPI", "Streamlit", "Gradio", "OpenCV", "ONNX Runtime", "TensorRT"],
    "SKILL_MLOPS": ["Kubernetes", "Docker", "AWS", "GCP", "Azure", "MLflow", "Weights & Biases", "Ray", "Apache Kafka", "Airflow", "Feast", "KServe", "Triton Inference Server", "Terraform", "Prometheus/Grafana", "Datadog"],
    "PROJECT_1_TITLE": "グローバルサポート向け多言語RAGアシスタント",
    "PROJECT_1_CHALLENGE": "8言語で月12万件超のチケットを処理するサポート組織において、回答のばらつきと中央値36時間の解決時間が課題でした。手作業のトリアージとナレッジ検索によりコストが上昇し、非英語市場のCSATが低迷していました。",
    "PROJECT_1_SOLUTION": "多言語埋め込みとベクトル検索（FAISS/PGVector）、会話ログで微調整した蒸留LLM（Llama 3.1 8B）による本番RAGを構築。忠実性・有害性・バイアスの評価基盤、キャッシュ、プロンプトのバージョン管理、安全ガードレールを実装。Streamlitのst.chatで役割ベースのUI、分析、監査ログを提供。",
    "PROJECT_1_IMPACT": "90日で42%のチケットを自己解決化、解決中央値を68%短縮、チケット単価を35%削減、非英語圏CSATを+12pt改善、Blue/Greenで稼働率99.9%を達成。",
    "PROJECT_2_TITLE": "製造業向けリアルタイム・エッジ画像検査",
    "PROJECT_2_CHALLENGE": "高スループットの組立ラインで微小欠陥の見逃しが発生し、返品や保証対応を招いていました。人手検査はスループットと品質のばらつきの要因で、逸脱率1.8%、平均サイクル7.5秒がボトルネックでした。",
    "PROJECT_2_SOLUTION": "ターゲット増強とハードネガティブを用いたカスタムYOLOv8を学習し、PruningとINT8量子化でTensorRT（NVIDIA Jetson）へ最適化。Triton/KServeでGPUオートスケール配備、OpenCVで前後処理。Streamlit（st.image）でリアルタイムQA、ドリフト監視、現場フィードバックを可視化。",
    "PROJECT_2_IMPACT": "本番でRecall 98.7%、Precision 96.2%、サイクルを3.1秒へ短縮、逸脱率0.3%へ低減、スクラップ22%削減、OEEを6.4pt改善。"
  },
  "zh": {
    "HEADLINE": "让可信的AI快速落地到生产",
    "SUMMARY_TITLE": "以结果为导向的AI工程师",
    "SUMMARY_P1": "专注于将前沿研究转化为可衡量的业务价值，打造面向生产的AI系统。核心领域涵盖大语言模型（LLM）、RAG（检索增强生成）与计算机视觉，强调企业级可靠性、合规与成本效率。",
    "SUMMARY_P2": "从模型选择与微调到大规模推理与监控，提供端到端能力：数据管道、评测框架、时延/成本优化、可观测性与安全护栏。与产品、安全、基础设施团队协同，确保AI功能按时上线并稳定扩展。",
    "SUMMARY_P3": "能够用清晰的语言向管理层与工程团队解释复杂技术，并将战略落到执行。曾交付多语言RAG助理、边缘侧实时视觉检测与自动化ML平台，均实现量化成果并遵循严格的MLOps实践。",
    "SKILLS_TITLE": "技术专长",
    "SKILL_LANGUAGES": ["Python", "TypeScript", "JavaScript", "Go", "SQL", "Bash", "C++"],
    "SKILL_FRAMEWORKS": ["PyTorch", "TensorFlow", "JAX", "Hugging Face Transformers", "LangChain", "LlamaIndex", "OpenAI API", "FastAPI", "Streamlit", "Gradio", "OpenCV", "ONNX Runtime", "TensorRT"],
    "SKILL_MLOPS": ["Kubernetes", "Docker", "AWS", "GCP", "Azure", "MLflow", "Weights & Biases", "Ray", "Apache Kafka", "Airflow", "Feast", "KServe", "Triton Inference Server", "Terraform", "Prometheus/Grafana", "Datadog"],
    "PROJECT_1_TITLE": "面向全球客服的多语言RAG助理",
    "PROJECT_1_CHALLENGE": "全球客服团队每月处理12万+多语言工单，答案不一致且中位解决时长达36小时。人工分流与知识检索导致高成本，非英语市场CSAT偏低。",
    "PROJECT_1_SOLUTION": "构建生产级RAG：跨语言向量表示与检索（FAISS/PGVector），蒸馏LLM（Llama 3.1 8B）基于会话转录微调；完善评测（忠实度/有害性/偏见）、缓存、Prompt版本管理与安全护栏。提供基于Streamlit的st.chat界面，支持RBAC、分析与审计日志。",
    "PROJECT_1_IMPACT": "90天内工单自助化率提升至42%，中位解决时长缩短68%，单工单成本降低35%，非英语市场CSAT提升+12点，借助蓝绿发布实现99.9%可用性。",
    "PROJECT_2_TITLE": "制造产线的边缘侧实时视觉质检",
    "PROJECT_2_CHALLENGE": "高速装配线存在微缺陷漏检，引发退货与保修。人工质检限制产能且波动大：漏检率1.8%，平均节拍7.5秒成为瓶颈。",
    "PROJECT_2_SOLUTION": "训练定制YOLOv8（目标增强+硬负样本），并进行剪枝与INT8量化，针对NVIDIA Jetson的TensorRT优化。通过Triton/KServe部署并启用GPU自动伸缩，OpenCV完成前后处理。借助Streamlit（st.image）实现实时质检看板、漂移监控与一线反馈闭环。",
    "PROJECT_2_IMPACT": "生产环境Recall 98.7%、Precision 96.2%，节拍缩短至3.1秒，漏检率降至0.3%，报废率下降22%，OEE提升6.4个百分点。"
  }
}
